{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f4dfa0d7-b1e8-44f2-bd10-c62a9d67e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4487eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, features, labels, device=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx].to(self.device)\n",
    "        label = self.labels[idx].to(self.device)\n",
    "        return feature, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "532ad725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dropout_rate=0.5):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_features, 256)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.encoder_layer_1 = nn.Linear(256, 128)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.bottleneck_layer = nn.Linear(128, 64)\n",
    "\n",
    "        self.decoder_layer_1 = nn.Linear(64, 128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.decoder_layer_2 = nn.Linear(128, 256)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(256)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        self.output_layer = nn.Linear(256, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.batch_norm1(self.input_layer(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.batch_norm2(self.encoder_layer_1(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.bottleneck_layer(x))  \n",
    "\n",
    "        x = torch.relu(self.batch_norm3(self.decoder_layer_1(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.batch_norm4(self.decoder_layer_2(x)))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = torch.relu(self.batch_norm1(self.input_layer(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.batch_norm2(self.encoder_layer_1(x)))\n",
    "        x = self.dropout2(x)\n",
    "        return self.bottleneck_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8c48a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_features, dropout_rate=0.5):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_features, 128)  \n",
    "        self.dropout1 = nn.Dropout(dropout_rate) \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.dropout2 = nn.Dropout(dropout_rate) \n",
    "        self.fc3 = nn.Linear(64, 32)  \n",
    "        self.dropout3 = nn.Dropout(dropout_rate) \n",
    "        self.fc4 = nn.Linear(32, 1)  \n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        x = self.dropout1(x)  \n",
    "        x = torch.relu(self.fc2(x)) \n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x)) \n",
    "        x = self.dropout3(x) \n",
    "        x = self.fc4(x) \n",
    "        x = self.sigmoid(x)  \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e33c0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(algorithm, train_loss, test_loss, accuracy, auc, file_name,description,disease,valid = False):\n",
    "    result = {\n",
    "        'Algorithm': algorithm,\n",
    "        'Disease': disease,\n",
    "        'Valid': valid,\n",
    "        'Train Loss': train_loss,\n",
    "        'Test Loss': test_loss,\n",
    "        'Test Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Timestamp': datetime.now(),\n",
    "        'description':description\n",
    "    }\n",
    "    file_path = 'results\\\\' + file_name \n",
    "    if not os.path.exists(file_path):\n",
    "        results_df = pd.DataFrame([result])\n",
    "        results_df.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        results_df = pd.DataFrame([result])\n",
    "        results_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "\n",
    "def train_classifier(model, train_loader, test_loader, loss_fn, optimizer, disease, algorithm, description, device=device, epochs=1000, patience=50, min_delta=0):\n",
    "    best_test_loss = np.inf\n",
    "    epochs_without_improvement = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "                predicted = (outputs >= 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        auc = roc_auc_score(all_labels, all_outputs)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f} \"\n",
    "              f\"Test Loss: {test_loss:.4f} \"\n",
    "              f\"Test Accuracy: {accuracy:.2f}% \"\n",
    "              f\"AUC: {auc:.4f}\")\n",
    "\n",
    "        if test_loss < best_test_loss - min_delta:\n",
    "            best_test_loss = test_loss\n",
    "            epochs_without_improvement = 0  \n",
    "            best_model_state = model.state_dict() \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            save_results_to_csv(algorithm,\n",
    "                                train_loss=train_loss,\n",
    "                                test_loss=test_loss,\n",
    "                                accuracy=accuracy,\n",
    "                                auc=auc,\n",
    "                                file_name='result.csv',\n",
    "                                disease=disease, valid=True,\n",
    "                                description=description)\n",
    "            break\n",
    "\n",
    "        if epoch == epochs - 1 or epochs_without_improvement >= patience:\n",
    "            save_results_to_csv(algorithm,\n",
    "                                train_loss=train_loss,\n",
    "                                test_loss=test_loss,\n",
    "                                accuracy=accuracy,\n",
    "                                auc=auc,\n",
    "                                file_name='result.csv',\n",
    "                                disease=disease, valid=True,\n",
    "                                description=description)\n",
    "\n",
    "    if 'best_model_state' in locals():\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8f7ccf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_log_transform(features):\n",
    "    return np.log(features + 1e-6) \n",
    "\n",
    "def apply_variance_thresholding(feature,variance_threshold):\n",
    "    feature_variances = np.var(feature, axis=0) \n",
    "    feature = feature[:, feature_variances > variance_threshold]\n",
    "    return feature\n",
    "\n",
    "def select_top_k_feature_from_random_forest(n_estimators,feature,ratio,df):\n",
    "        rf = RandomForestClassifier(n_estimators, random_state=42)\n",
    "        rf.fit(feature, df['disease'].apply(lambda x: 0 if x == 'healthy' else 1))\n",
    "        feature_importances = rf.feature_importances_\n",
    "        total_features = feature.shape[1]\n",
    "        k = math.floor((total_features*ratio))  \n",
    "        top_k_features = np.argsort(feature_importances)[-k:]\n",
    "        feature = feature[:, top_k_features]\n",
    "        return feature\n",
    "    \n",
    "def select_feature_from_autoencoder(model, feature, epochs=500, device=device, patience=10):\n",
    "\n",
    "    model.train()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    feature_tensor = torch.Tensor(feature).to(device=device)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        acc_loss = 0\n",
    "        for batch in DataLoader(feature_tensor, batch_size=64, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(device=device)\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(output, batch)\n",
    "            acc_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = acc_loss / len(feature_tensor) \n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.5f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0  \n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    model.eval()\n",
    "    encoded_features = model.encode(feature_tensor)\n",
    "    return encoded_features.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Define log----------------------\n",
    "algorithm = 'log_transform+variance_threshold+auto_encoder+normalization+early_stopping'\n",
    "description = 'variance_threshold=0.2'\n",
    "\n",
    "#-----------Define disease file map---------------\n",
    "disease_file_map = {\n",
    "    'Cirrhosis': 'cirrhosis_10fold.csv',\n",
    "    'CRC': 'CRC_10fold.csv',\n",
    "    'CRC_AUS': 'CRC_AUS_LOSO.csv',\n",
    "    'CRC_CHI': 'CRC_CHI_LOSO.csv',\n",
    "    'CRC_FRA': 'CRC_FRA_LOSO.csv',\n",
    "    'CRC_GER': 'CRC_GER_LOSO.csv',\n",
    "    'CRC_IND': 'CRC_IND_additional.csv',\n",
    "    'CRC_USA': 'CRC_USA_LOSO.csv',\n",
    "    'IBD': 'IBD_10fold.csv',\n",
    "    'IBD_DK': 'IBD_DK_LOSO.csv',\n",
    "    'IBD_UK': 'IBD_UK_LOSO.csv',\n",
    "    'Obt': 'Obt_10fold.csv',\n",
    "    'T2D': 'T2D_10fold.csv'\n",
    "}\n",
    "\n",
    "for disease, file_name in disease_file_map.items():\n",
    "    \n",
    "    for iteration in range(5):\n",
    "        \n",
    "        print('-------------' + 'disease: ' + disease + ' | ' + 'iteration: ' + str(iteration))\n",
    "\n",
    "    #---------- read data from csv-----------------\n",
    "        raw_df = pd.read_csv('data\\\\' + disease_file_map[disease])\n",
    "        raw_df['disease'] = raw_df['disease'].apply(lambda x: 0 if x == 'healthy' else 1)\n",
    "        feature = raw_df.iloc[:, 4:].values \n",
    "\n",
    "        # ---------- feature selection algorithm -----------------\n",
    "        # 1. Log Transformation (Optional)\n",
    "        feature = apply_log_transform(features=feature)\n",
    "\n",
    "        # 2. Variance Thresholding\n",
    "        feature = apply_variance_thresholding(feature=feature,variance_threshold=0.2)\n",
    "\n",
    "        # 3. apply auto encoder \n",
    "        input_features = feature.shape[1]\n",
    "        autoencoder = AutoEncoder(input_features=input_features, output_features=input_features).to(device=device)\n",
    "        encoded_features = select_feature_from_autoencoder(model=autoencoder, feature=feature)\n",
    "\n",
    "        # 4. Normalization (Min-Max scaling between 0 and 1)\n",
    "        feature_min = np.min(encoded_features, axis=0)\n",
    "        feature_max = np.max(encoded_features, axis=0)\n",
    "        feature = (encoded_features - feature_min) / (feature_max - feature_min + 1e-6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #---------- convert label and feature into tensor-----------------\n",
    "        label = torch.tensor(raw_df.loc[:, 'disease'].values).unsqueeze(1).float().to(device=device) \n",
    "        feature = torch.Tensor(feature).to(device=device)\n",
    "\n",
    "\n",
    "        #----------split tensor into training set and test set-----------------\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(feature, label, test_size=0.2)\n",
    "\n",
    "        #----------define data loader------------------\n",
    "        train_loader =  DataLoader(TensorDataset(feature_train,label_train), batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(TensorDataset(feature_test,label_test), batch_size=64, shuffle=True)\n",
    "\n",
    "        #----------define classifier model-----------------\n",
    "        classifier = BinaryClassifier(input_features=feature_train.shape[1]).to(device=device)\n",
    "\n",
    "\n",
    "        #---------define loss function and optimizer----------\n",
    "        loss_fn = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            classifier.parameters(),\n",
    "            lr=0.0001,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "        #---------train the classifier model-------------\n",
    "        train_classifier(\n",
    "            model=classifier,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=1000,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            disease=disease,\n",
    "            algorithm=algorithm,\n",
    "            description = description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('results\\\\result.csv')\n",
    "\n",
    "# Define the algorithms (including the new one)\n",
    "algorithms = [\n",
    "    'raw+early_stopping', \n",
    "    'log_transform+variance_threshold+normalization+early_stopping', \n",
    "    'log_transform+variance_threshold+normalization+early_stopping+random_forest',\n",
    "    'log_transform+variance_threshold+auto_encoder+normalization+early_stopping'  # New algorithm\n",
    "]\n",
    "\n",
    "# Colors for each algorithm; use dark green for the AE bar, blue for AE error line\n",
    "colors = ['black', 'red', 'blue', '#006400']\n",
    "error_colors = ['red', 'black', 'green', 'blue']  # Use blue for AE error line\n",
    "\n",
    "# Get unique diseases\n",
    "diseases = data['Disease'].unique()\n",
    "\n",
    "# Split diseases into three groups\n",
    "disease_groups = [\n",
    "    diseases[:4],   # First 4 diseases\n",
    "    diseases[4:8],  # Next 4 diseases\n",
    "    diseases[8:]    # Remaining diseases (5)\n",
    "]\n",
    "\n",
    "def create_single_group_plot(disease_group_data, diseases_in_group, group_idx):\n",
    "    num_diseases = len(diseases_in_group)\n",
    "    \n",
    "    # Create the plot with sufficient space for the groups\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Set the background to white\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    positions = np.arange(num_diseases)  # The x locations for the diseases\n",
    "    width = 0.2  # The width of the bars (adjusted for four bars)\n",
    "\n",
    "    # Lists to store means and std deviations for each algorithm\n",
    "    algorithm_means = [[] for _ in algorithms]\n",
    "    algorithm_stds = [[] for _ in algorithms]\n",
    "\n",
    "    for disease in diseases_in_group:\n",
    "        disease_data = disease_group_data[disease_group_data['Disease'] == disease]\n",
    "        \n",
    "        # Calculate statistics for each algorithm\n",
    "        for algo_idx, algo in enumerate(algorithms):\n",
    "            algo_data = disease_data[disease_data['Algorithm'] == algo]\n",
    "            auc_values = algo_data['AUC'].astype(float)\n",
    "            mean_auc = auc_values.mean()\n",
    "            std_auc = auc_values.std()\n",
    "            \n",
    "            algorithm_means[algo_idx].append(mean_auc)\n",
    "            algorithm_stds[algo_idx].append(std_auc)\n",
    "    \n",
    "    # Create the bars for each algorithm\n",
    "    bars = []\n",
    "    for i, (means, stds, color, err_color) in enumerate(zip(algorithm_means, algorithm_stds, colors, error_colors)):\n",
    "        bars.append(ax.bar(\n",
    "            positions + (i - 1.5) * width, means, width, color=color, yerr=stds,\n",
    "            error_kw=dict(elinewidth=2, ecolor=err_color)\n",
    "        ))\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel('Diseases', color='black')\n",
    "    ax.set_ylabel('AUC', color='black')\n",
    "    ax.set_title('AUC Performance Comparison Across Diseases and Algorithms', color='black')\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(diseases_in_group, rotation=45, color='black')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Ensure axis lines and ticks are visible\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    \n",
    "    # Make sure all text is black\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_color('black')\n",
    "    \n",
    "    # Add the text labels inside the bars (centered horizontally and vertically) with rotation\n",
    "    algo_labels = ['R', 'LVN', 'LVN-RF', 'LVN-AE']\n",
    "    for i, (bar_group, label) in enumerate(zip(bars, algo_labels)):\n",
    "        for rect in bar_group:\n",
    "            height = rect.get_height()\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2, height / 2, label,\n",
    "                ha='center', va='center', color='white', fontweight='bold', rotation=90  # Rotate label by 90 degrees\n",
    "            )\n",
    "            # Add the maximum value at the top of the bar\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2, height + 0.02, f'{height:.2f}',\n",
    "                ha='center', va='bottom', color='black', fontweight='bold'\n",
    "            )\n",
    "    \n",
    "    # Save the figure\n",
    "    os.makedirs('graphs', exist_ok=True)\n",
    "    fig.savefig(f'{\"graphs\"}/auc_comparison_group_{group_idx}.png', bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "# Create plots for each disease group\n",
    "for group_idx, disease_group in enumerate(disease_groups):\n",
    "    group_data = data[data['Disease'].isin(disease_group)]\n",
    "    create_single_group_plot(group_data, disease_group, group_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
